{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "Xrk4wG1VTixk",
    "outputId": "616d2c0e-a183-4e16-8c33-40733f083292"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'bert'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/google-research/bert.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "GJUcQX2FTtOF",
    "outputId": "41487f44-7f8a-4cc6-e247-aed5e66c6ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s’appelle Acer\n",
      " Le numéro de série du volume est FA87-4F74\n",
      "\n",
      " Répertoire de C:\\Users\\H\\Desktop\\NLP_Project\\NLP\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier introuvable\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TH3m63MZTv1S",
    "outputId": "738e45b8-f2af-4468-f1e4-013c348fe6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\H\\Desktop\\NLP_Project\\NLP\\bert\n"
     ]
    }
   ],
   "source": [
    "cd bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8pCSIW_e86F"
   },
   "source": [
    "### **BERT repository files**\n",
    "\n",
    "\n",
    "> use ls -l to check the content inside BERT folder, you can see all files related to BERT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "colab_type": "code",
    "id": "JvzhLkIOTyPa",
    "outputId": "056212a9-d9df-4c5f-99b4-2466aff96fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s’appelle Acer\n",
      " Le numéro de série du volume est FA87-4F74\n",
      "\n",
      " Répertoire de C:\\Users\\H\\Desktop\\NLP_Project\\NLP\\bert\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier introuvable\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "czm6QjyIUWXA",
    "outputId": "7c3b0d53-8d49-444d-fd54-3847e677d217"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "sZAccizWUppZ",
    "outputId": "8302a432-6900-48e5-f4de-81045d4a397e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "# Unzip the pretrained model\n",
    "!unzip uncased_L-24_H-1024_A-16.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "IrqrX9oSVdAB",
    "outputId": "2978fff5-1fde-468e-f839-bf59291c2811"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n",
      "'wget' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "#Download the SQUAD train and dev dataset\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
    "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C79T4RubUlg0"
   },
   "source": [
    "### **Set up your TPU environment**\n",
    "*   Verify that you are connected to a TPU device\n",
    "*   You will get know your TPU Address that is used at time of fine-tuning\n",
    "*   Perform Google Authentication to access your bucket\n",
    "*   Upload your credentials to TPU to access your GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "ZaMvs7N5VR62",
    "outputId": "da76ecc7-f281-4d11-e45d-259f27fee748"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ca5488d958e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;34m'COLAB_TPU_ADDR'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mTPU_ADDRESS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'grpc://'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TPU address is => '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTPU_ADDRESS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
    "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "print('TPU address is => ', TPU_ADDRESS)\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "with tf.Session(TPU_ADDRESS) as session:\n",
    "  print('TPU devices:')\n",
    "  pprint.pprint(session.list_devices())\n",
    "\n",
    "  # Upload credentials to TPU.\n",
    "  with open('/content/adc.json', 'r') as f:\n",
    "    auth_info = json.load(f)\n",
    "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
    "  # Now credentials are set for all future sessions on this TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYAwq7V3W6hx"
   },
   "source": [
    "### **Create output directory** \n",
    "\n",
    "\n",
    "> Need to create a output directory at GCS (Google Cloud Storage) bucket, where you will get your fine_tuned model after training completion. For that you need to provide your BUCKET name and OUPUT DIRECTORY name.\n",
    "\n",
    "> Also need to move Pre-trained Model at GCS (Google Cloud Storage) bucket, as Local File System is not Supported on TPU. If you don't move your pretrained model to TPU you may face an error. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eKAVNzc9XLwi",
    "outputId": "6703aa68-072c-49a2-f495-bb0bed5eedcc"
   },
   "outputs": [],
   "source": [
    "BUCKET = 'bertnlpdemo' #@param {type:\"string\"}\n",
    "assert BUCKET, '*** Must specify an existing GCS bucket name ***'\n",
    "output_dir_name = 'bert_output' #@param {type:\"string\"}\n",
    "BUCKET_NAME = 'gs://{}'.format(BUCKET)\n",
    "OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET,output_dir_name)\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0jag_0jlWVk"
   },
   "source": [
    "### **Move Pretrained Model to GCS Bucket** \n",
    "\n",
    "\n",
    "> Need to move Pre-trained Model at GCS (Google Cloud Storage) bucket, as Local File System is not Supported on TPU. If you don't move your pretrained model to TPU you may face the error. \n",
    "\n",
    "\n",
    "\n",
    "> The **gsutil** **mv** command allows you to move data between your local file system and the cloud, move data within the cloud, and move data between cloud storage providers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "colab_type": "code",
    "id": "Stoc3soekzkT",
    "outputId": "41baa60f-d408-4012-9d51-a5b010ad8778"
   },
   "outputs": [],
   "source": [
    "!gsutil mv /content/bert/uncased_L-24_H-1024_A-16 $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_ozhC2vaHUe"
   },
   "source": [
    "### **Training**\n",
    "\n",
    "> Below is the command to run the training. To run the training on TPU you need to make sure about below Hyperparameter, that is tpu must be true and provide the tpu_address that we have find out above.\n",
    "\n",
    "1.   --use_tpu=True\n",
    "2.   --tpu_name=YOUR_TPU_ADDRESS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WwBETmjSCrsN",
    "outputId": "cd94f0d6-5590-4fc4-bea0-a4abbb211fa0"
   },
   "outputs": [],
   "source": [
    "!python run_squad.py \\\n",
    "  --vocab_file=$BUCKET_NAME/uncased_L-24_H-1024_A-16/vocab.txt \\\n",
    "  --bert_config_file=$BUCKET_NAME/uncased_L-24_H-1024_A-16/bert_config.json \\\n",
    "  --init_checkpoint=$BUCKET_NAME/uncased_L-24_H-1024_A-16/bert_model.ckpt \\\n",
    "  --do_train=True \\\n",
    "  --train_file=train-v2.0.json \\\n",
    "  --do_predict=True \\\n",
    "  --predict_file=dev-v2.0.json \\\n",
    "  --train_batch_size=24 \\\n",
    "  --learning_rate=3e-5 \\\n",
    "  --num_train_epochs=2.0 \\\n",
    "  --use_tpu=True \\\n",
    "  --tpu_name=grpc://10.1.118.82:8470 \\\n",
    "  --max_seq_length=384 \\\n",
    "  --doc_stride=128 \\\n",
    "  --version_2_with_negative=True \\\n",
    "  --output_dir=$OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAptznnCdX8d"
   },
   "source": [
    "### **Create Testing File**\n",
    "\n",
    "\n",
    "> We are creating input_file.json as a blank json file and then writing the data in SQUAD format in the file.\n",
    "\n",
    "\n",
    "*   **touch** is used to create a file\n",
    "*   **%%writefile** is used to write a file in the colab\n",
    "\n",
    "\n",
    "\n",
    "> You can pass your own questions and context in the below file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoT__iSecn-B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'touch' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!touch input_file.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "QrxuoRNCcsnf",
    "outputId": "f4e3dc9a-3b89-45c0-b5eb-4498e3f4c0e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input_file.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_file.json\n",
    "{\n",
    "    \"version\": \"v2.0\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"title\": \"your_title\",\n",
    "            \"paragraphs\": [\n",
    "                {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"question\": \"Who is current CEO?\",\n",
    "                            \"id\": \"56ddde6b9a695914005b9628\",\n",
    "                            \"is_impossible\": \"\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"question\": \"Who founded google?\",\n",
    "                            \"id\": \"56ddde6b9a695914005b9629\",\n",
    "                            \"is_impossible\": \"\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"question\": \"when did IPO take place?\",\n",
    "                            \"id\": \"56ddde6b9a695914005b962a\",\n",
    "                            \"is_impossible\": \"\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"context\": \"Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock. They incorporated Google as a privately held company on September 4, 1998. An initial public offering (IPO) took place on August 19, 2004, and Google moved to its headquarters in Mountain View, California, nicknamed the Googleplex. In August 2015, Google announced plans to reorganize its various interests as a conglomerate called Alphabet Inc. Google is Alphabet's leading subsidiary and will continue to be the umbrella company for Alphabet's Internet interests. Sundar Pichai was appointed CEO of Google, replacing Larry Page who became the CEO of Alphabet.\"                \n",
    "                 }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E9MDvLtUd6xs"
   },
   "source": [
    "### **Prediction**\n",
    "\n",
    "\n",
    "> Below is the command to perform your own custom prediction, that is you can change the input_file.json by providing your paragraph and questions after then execute the below command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "VEYz_OxzY-sX",
    "outputId": "aa179d0e-4127-4a53-c7e8-273fd8c8b0aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-06 15:33:22.642501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\n",
      "Traceback (most recent call last):\n",
      "  File \"run_squad.py\", line 27, in <module>\n",
      "    import optimization\n",
      "  File \"C:\\Users\\H\\Desktop\\NLP_Project\\NLP\\bert\\optimization.py\", line 87, in <module>\n",
      "    class AdamWeightDecayOptimizer(tf.train.Optimizer):\n",
      "AttributeError: module 'tensorflow_core._api.v2.train' has no attribute 'Optimizer'\n"
     ]
    }
   ],
   "source": [
    "!python run_squad.py \\\n",
    "  --vocab_file=$BUCKET_NAME/uncased_L-24_H-1024_A-16/vocab.txt \\\n",
    "  --bert_config_file=$BUCKET_NAME/uncased_L-24_H-1024_A-16/bert_config.json \\\n",
    "  --init_checkpoint=$OUTPUT_DIR/model.ckpt-10859 \\\n",
    "  --do_train=False \\\n",
    "  --max_query_length=30  \\\n",
    "  --do_predict=True \\\n",
    "  --predict_file=input_file.json \\\n",
    "  --predict_batch_size=8 \\\n",
    "  --n_best_size=3 \\\n",
    "  --max_seq_length=384 \\\n",
    "  --doc_stride=128 \\\n",
    "  --output_dir=output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Question Answering System using BERT + SQuAD 2.0 on Colab TPU",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
